diff --git a/backend.c b/backend.c
index 2f46329..7b19ede 100644
--- a/backend.c
+++ b/backend.c
@@ -863,10 +863,23 @@ static void handle_thinktime(struct thread_data *td, enum fio_ddir ddir)
 	uint64_t total;
 	int left;
 
-	b = ddir_rw_sum(td->io_blocks);
-	if (b % td->o.thinktime_blocks)
+    b = ddir_rw_sum(td->io_issues);
+	if (b != td->next_thinktime_blocks)
 		return;
 
+    // Now reset thinktime to something different
+    if (td->o.iodepth == 1)
+        td->o.thinktime_blocks = 1;
+    else {
+        do {
+            td->o.thinktime_blocks = __rand(&td->random_state) % td->o.iodepth;
+        } while (td->o.thinktime_blocks == 0);
+    }
+    // We also set iodepth_batch to the same as thinktime, since the io engine doesn't even bother to
+    // check for thinktime_blocks until iodepth_batch blocks are submitted
+    td->next_thinktime_blocks += td->o.thinktime_blocks;
+    td->o.iodepth_batch = td->o.thinktime_blocks;
+
 	io_u_quiesce(td);
 
 	total = 0;
@@ -1061,7 +1074,7 @@ static void do_io(struct thread_data *td, uint64_t *bytes_done)
 
 		} else {
 			ret = io_u_submit(td, io_u);
-
+            
 			if (should_check_rate(td))
 				td->rate_next_io_time[ddir] = usec_for_io(td, ddir);
 
@@ -1079,8 +1092,13 @@ reap:
 			if (full || io_in_polling(td))
 				ret = wait_for_completions(td, &comp_time);
 		}
+
 		if (ret < 0)
 			break;
+        if (ddir_rw_sum(td->io_issues) == td->next_thinktime_blocks) {
+		    if (ddir_rw(ddir) && td->o.thinktime)
+			    handle_thinktime(td, ddir);
+        }
 		if (!ddir_rw_sum(td->bytes_done) &&
 		    !td_ioengine_flagged(td, FIO_NOIO))
 			continue;
@@ -1093,13 +1111,14 @@ reap:
 				break;
 			}
 		}
+
 		if (!in_ramp_time(td) && td->o.latency_target)
 			lat_target_check(td);
 
 		if (ddir_rw(ddir) && td->o.thinktime)
 			handle_thinktime(td, ddir);
 	}
-
+            
 	check_update_rusage(td);
 
 	if (td->trim_entries)
@@ -1210,6 +1229,8 @@ static int init_io_u(struct thread_data *td)
 	int cl_align, i, max_units;
 	int err;
 
+    td->next_thinktime_blocks = td->o.thinktime_blocks;
+
 	max_units = td->o.iodepth;
 
 	err = 0;
diff --git a/engines/libaio.c b/engines/libaio.c
index 8844ac8..5e58ffc 100644
--- a/engines/libaio.c
+++ b/engines/libaio.c
@@ -20,6 +20,10 @@
 #define IOCB_FLAG_HIPRI	(1 << 2)
 #endif
 
+#ifndef IOCB_FLAG_BARRIER
+#define IOCB_FLAG_BARRIER	(1 << 9)
+#endif
+
 #ifndef IOCTX_FLAG_IOPOLL
 #define IOCTX_FLAG_IOPOLL	(1 << 0)
 #endif
@@ -53,6 +57,7 @@ struct libaio_options {
 	void *pad;
 	unsigned int userspace_reap;
 	unsigned int hipri;
+	unsigned int barrier;
 };
 
 static struct fio_option options[] = {
@@ -75,6 +80,15 @@ static struct fio_option options[] = {
 		.group	= FIO_OPT_G_LIBAIO,
 	},
 	{
+		.name	= "barrier",
+		.lname	= "High Priority",
+		.type	= FIO_OPT_STR_SET,
+		.off1	= offsetof(struct libaio_options, barrier),
+		.help	= "Use polled IO completions",
+		.category = FIO_OPT_C_ENGINE,
+		.group	= FIO_OPT_G_LIBAIO,
+	},
+	{
 		.name	= NULL,
 	},
 };
@@ -271,6 +285,7 @@ static void fio_libaio_queued(struct thread_data *td, struct io_u **io_us,
 
 static int fio_libaio_commit(struct thread_data *td)
 {
+	struct libaio_options *o = td->eo;
 	struct libaio_data *ld = td->io_ops_data;
 	struct iocb **iocbs;
 	struct io_u **io_us;
@@ -286,6 +301,11 @@ static int fio_libaio_commit(struct thread_data *td)
 		nr = min((unsigned int) nr, ld->entries - ld->tail);
 		io_us = ld->io_us + ld->tail;
 		iocbs = ld->iocbs + ld->tail;
+    
+        //fprintf(stderr, "nr in libaio: %d\n", nr);
+		
+		if (o->barrier)
+			iocbs[nr-1]->u.c.flags |= IOCB_FLAG_BARRIER;
 
 		ret = io_submit(ld->aio_ctx, nr, iocbs);
 		if (ret > 0) {
diff --git a/fio.h b/fio.h
index b3ba5db..68f4475 100644
--- a/fio.h
+++ b/fio.h
@@ -460,6 +460,8 @@ struct thread_data {
 	CUdeviceptr dev_mem_ptr;
 #endif	
 
+    unsigned long long next_thinktime_blocks;
+
 };
 
 /*
